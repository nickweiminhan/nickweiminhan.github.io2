---
layout:     post
title:      "2025-06-06-周五"
subtitle:   "06-06-周五"
date:       2025-06-06 21:00:06
author:     "Nickwei"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 随笔
---

## 面试总结





### 2. 题库与实验教程

前五个认证包含实验考试，但实验考试不单独生成证书。38 元的微认证通常不含实验考试。

**实验环境常见问题及配置提示：**

实验考试的云服务器默认安全组未开放22端口。需手动配置安全组，建议直接开放常用端口。

容器镜像拉取失败时，需配置镜像加速器。 华为云配置路径：**控制台** -> **容器镜像服务 SWR** -> **镜像资源** -> **镜像中心** -> **镜像加速器** (可复制命令配置华为源)。

如果华为源缺少部分镜像，可尝试 **1panel** 镜像源：

<BASH>

```
sudo vim /etc/docker/daemon.json
```

文件内容：

<JSON>



```
{  "registry-mirrors": ["https://docker.1panel.live"]}
```

然后执行：

<BASH>

```
sudo systemctl daemon-reloadsudo systemctl restart dockerdocker info
```

上传 **kubectl** 配置文件示例：

<BASH>

```
user@sandbox:~/Downloads$ lscce-k8s-kubeconfig.yamluser@sandbox:~/Downloads$ realpath cce-k8s-kubeconfig.yaml/home/Downloads/cce-k8s-kubeconfig.yamluser@sandbox:~/Downloads$ scp /home/Downloads/cce-k8s-kubeconfig.yaml root@xx.xx.xx.xx:/home
```

云数据库 **RDS** 的安全组默认可能未放行端口，需配置并绑定弹性IP。

官方题目中镜像名可能误写为 `niginx:1.7.9`，按题目要求操作即可，不影响步骤。

若不熟悉华为云 **云容器引擎 CCE** 服务购买，可参考官方文档：**在CCE集群中部署NGINX无状态工作负载**。

**附实验考试题目和AI答案（人工订正，如有错误请再咨询AI获取详细命令）：**

**云原生基础设施之容器入门**

**任务1：Dockerfile 构建容器镜像**

**得分点：**能正确创建名为 `httpd:v1` 的镜像并正常运行。

Dockerfile 参数示例： ① 基础镜像：`httpd` ② 维护者：`123@huawei.com` ③ 端口：`80` ④ 运行命令：`echo "dockerfile test" > /usr/local/apache2/htdocs/index.html`

**Dockerfile 模板参考：**

<DOCKERFILE>

```
FROM centos:centos7MAINTAINER Iris@huawei.comEXPOSE 80RUN yum install -y httpd vi && yum clean all
```

使用 `docker run -p 80:80 ...` 运行容器。浏览器访问 `http://EIP:80`，显示 `dockerfile test` 即表示成功。

**注意：** (1) 镜像命名错误不得分。 (2) 端口开放错误不得分。

**任务1步骤：**

创建 `Dockerfile` (无后缀名)，内容如下：

<DOCKERFILE>

```
FROM httpdMAINTAINER 123@huawei.comEXPOSE 80RUN echo "dockerfile test" > /usr/local/apache2/htdocs/index.html
```

在 `Dockerfile` 所在目录执行构建命令：

<BASH>

```
docker build -t httpd:v1 .
```

运行容器：

<BASH>

```
docker run -d -p 80:80 httpd:v1
```

验证：浏览器访问 `http://宿主机EIP:80` (宿主机公网IP)。显示 “dockerfile test” 即成功。

**任务2：搭建私有镜像仓库**

**得分点：**成功创建私有镜像仓库并成功上传镜像。

1. 搭建监听端口为5000的私有镜像仓库。修改 `httpd:v1` 镜像名称后上传至该仓库。
2. 终端执行 `curl -X GET http://localhost:5000/v2/httpd/tags/list`，结果为 `{"name":"httpd","tags":["v1"]}` 即完成。

**注意：** (1) 镜像仓库监听端口错误不得分。 (2) 镜像名称错误不得分。

**任务2步骤：**

运行私有镜像仓库容器 (registry)：

<BASH>

```
docker run -d -p 5000:5000 --restart=always --name registry registry:2
```

标记 `httpd:v1` 镜像以便上传 (若Docker无法解析localhost，需用宿主机IP；部分版本需配置insecure-registries)：

<BASH>

```
docker tag httpd:v1 localhost:5000/httpd:v1
```

**提示：**若Docker未配置信任 `localhost:5000`，推送会失败。需修改 `/etc/docker/daemon.json` 添加 `{"insecure-registries" : ["localhost:5000"]}` 并重启Docker。

上传镜像：

<BASH>

```
docker push localhost:5000/httpd:v1
```

验证仓库镜像信息：

<BASH>

```
curl -X GET http://localhost:5000/v2/httpd/tags/list
```

预期输出：

<JSON>



```
{"name":"httpd","tags":["v1"]}
```

**任务3：容器生命周期管理**

**得分点：**成功完成生命周期管理。

对 `httpd:v1` 容器及镜像执行暂停、恢复、停止、重启、删除操作。 执行 `docker rmi httpd:v1` 后，出现 `Untagged: httpd:v1` 即完成。

**注意：** (1) 操作目标错误或内容不符要求不得分。

**任务3步骤：**

确保存在基于 `httpd:v1` 运行的容器 (若无则先运行)：

<BASH>

```
docker run -d --name my_httpd_v1 httpd:v1
```

假设容器名为 `my_httpd_v1`。

暂停容器：

<BASH>

```
docker pause my_httpd_v1
```

恢复容器：

<BASH>

```
docker unpause my_httpd_v1
```

停止容器：

<BASH>

```
docker stop my_httpd_v1
```

重启容器 (若容器已停止，此操作会使其重新运行)。

停止并删除容器 (删除镜像前必须先停止并删除其容器)：

<BASH>

```
docker stop my_httpd_v1docker rm my_httpd_v1
```

若存在其他基于 `httpd:v1` 或 `localhost:5000/httpd:v1` 的容器，也需一并停止和删除。

删除本地私有仓库镜像标签 (若任务2已执行)：

<BASH>

```
docker rmi localhost:5000/httpd:v1
```

删除 `httpd:v1` 镜像：

<BASH>

```
docker rmi httpd:v1
```

预期输出包含：`Untagged: httpd:v1`

**云原生基础设施之容器进阶**

**任务1：使用 cgroup 实现资源限制**

**得分点：**能对容器实现CPU限制。

运行压力测试容器 `progrium/stress`，限制CPU使用率为70%。 在 `/sys/fs/cgroup/cpu/docker/容器ID/` 目录下执行 `cat cpu.cfs_quota_us`，显示 `70000` 即成功。

**注意：** (1) 限额比例错误不得分。 (2) 查看非 `cpu.cfs_quota_us` 文件或命令错误不得分。

**任务1步骤：**

拉取 `progrium/stress` 镜像 (注意镜像源配置)：

<BASH>

```
docker pull progrium/stress
```

运行容器并限制CPU (70%的一个核心)：

<BASH>

```
docker run -d --name my_stress --cpu-period=100000 --cpu-quota=70000 progrium/stress --cpu 1
```

获取容器完整ID：

<BASH>

```
docker ps --no-trunc | grep my_stress# 或 docker inspect --format='{{.Id}}' my_stress
```

验证CPU限额 (将 `[容器完整ID]` 替换为实际ID)：

<BASH>

```
cat /sys/fs/cgroup/cpu/docker/[容器完整ID]/cpu.cfs_quota_us
```

预期输出：`70000`

**任务2：搭建容器 bridge 网络**

**得分点：**成功搭建bridge网络并实现容器网络互通。

1. 创建用户自定义网桥，子网 `173.18.0.0/16`，网关 `173.18.0.1`。
2. 运行两个 `centos` 容器并挂载到自定义网桥。
3. 进入任一容器，ping通另一容器IP。

输入 `ping 173.18.0.2` 命令，有正常返回即完成。

**注意：** (1) 建议提前拉取 `centos` 镜像。

**任务2步骤：**

提前拉取 `centos` 镜像：

<BASH>

```
docker pull centos:latest
```

创建用户自定义网桥：

<BASH>

```
docker network create --subnet=173.18.0.0/16 --gateway=173.18.0.1 my_bridge_network
```

运行第一个容器 `container1` (IP `173.18.0.2`)：

<BASH>

```
docker run -dit --name container1 --network my_bridge_network --ip 173.18.0.2 centos:latest /bin/bash
```

运行第二个容器 `container2` (IP `173.18.0.3`)：

<BASH>

```
docker run -dit --name container2 --network my_bridge_network --ip 173.18.0.3 centos:latest /bin/bash
```

进入 `container1`：

<BASH>

```
docker exec -it container1 /bin/bash
```

在 `container1` 内安装 `ping` 并 ping `container2` (173.18.0.3)：

<BASH>

```
# 在container1的shell中yum install -y iputilsping 173.18.0.3
```

若题目要求从另一容器 ping `173.18.0.2`，则进入 `container2` 执行 `ping 173.18.0.2`。

**任务3：容器挂载存储卷**

**得分点：**成功挂载volume并实现持久化存储。

使用Docker managed volume挂载到容器，在容器内执行 `echo "this is page from docker managed volume. " > index.html`。删除容器。 在宿主机对应挂载路径下 `cat index.html`，内容为 “this is page from docker managed volume.” 即完成。

**注意：** (1) 可使用任意镜像 (如 `httpd`, `centos`)。

**任务3步骤：**

创建Docker managed volume：

<BASH>

```
docker volume create my_volume
```

运行容器并将 `my_volume` 挂载到 `/appdata` (使用 `tail -f /dev/null` 保持容器运行)：

<BASH>

```
docker run -d --name volume_test_container -v my_volume:/appdata centos:latest tail -f /dev/null
```

在容器内写入文件：

<BASH>

```
docker exec volume_test_container bash -c 'echo "this is page from docker managed volume." > /appdata/index.html'
```

删除容器：

<BASH>

```
docker stop volume_test_containerdocker rm volume_test_container
```

查看 `my_volume` 在宿主机的挂载点 (Mountpoint)：

<BASH>

```
docker volume inspect my_volume
```

在宿主机上查看文件内容 (将 `[Mountpoint路径]` 替换为实际路径，如 `/var/lib/docker/volumes/my_volume/_data`):

<BASH>

```
cat [Mountpoint路径]/index.html
```

预期输出：`this is page from docker managed volume.`

**云容器快速搭建网站**

**任务1：创建RDS数据库**

**得分点：**正确创建RDS for MySQL数据库服务。

参数要求： 计费模式：按需计费；区域：华北-北京四；实例名称：`rds-web` (必须为此名)；数据库引擎：MySQL 5.7；实例类型：单机；存储类型：默认；可用区：默认；性能规格：通用型|2核|4GB；存储空间：40GB；VPC/子网/安全组：选择已预置的。

**注意：** (1) 规格错误不得分。 (2) RDS创建后，需自行创建数据库、账号、密码并授权，供后续使用。

**任务1步骤：** 按控制台指引和上述参数创建RDS实例。务必配置安全组开放端口，并考虑绑定弹性IP以便访问。

**任务2：创建CCE集群并添加Node节点**

**得分点：**成功添加指定规格的Node节点。

CCE集群参数： 计费模式：按需计费；区域：华北-北京四；集群名称：`test` (必须为此名)；版本：最新版；集群管理规模：50节点；高可用：否；VPC/子网：选择已创建的；网络模型：容器隧道网络；容器网段：自动选择；服务网段：默认；插件：取消“容器监控”及“业务日志”。

Node节点参数： 计费方式：按需计费；区域：华北-北京四；可用区：默认；类型：弹性云服务器-虚拟机；容器引擎：默认；规格：通用型|s6.xlarge.2|4核|8GB；操作系统：EulerOS 2.9；名称：`test-node`；登录方式：密码 (自行设置)；存储：高IO，其余默认；VPC/子网：选择已预置的；IP：随机分配；弹性公网IP：自动创建 (按流量计费，带宽5M)；数量：1台。

**注意：** (1) 在新版CCE界面操作。 (2) 节点规格错误不得分。

**任务2步骤：** 通过华为云CCE控制台操作。

1. **创建集群**：按上述参数创建名为 `test` 的Kubernetes集群控制面。
2. **创建节点**：在 `test` 集群中，按上述参数创建名为 `test-node` 的工作节点。

**任务3：通过华为云镜像中心部署WordPress**

**得分点：**能通过 `http://IP:端口号` 成功访问WordPress登录页面。

WordPress无状态工作负载参数： 负载名称：`wordpress`；实例数量：1；镜像版本：`php7.3`；访问类型：LoadBalancer；访问端口：80；容器端口：80。

环境变量（4个）： `WORDPRESS_DB_HOST`：数据库内网IP:端口号 (如 `192.168.1.10:3306`) `WORDPRESS_DB_USER`：任务1中创建的RDS用户名 `WORDPRESS_DB_PASSWORD`：任务1中创建的RDS用户密码 `WORDPRESS_DB_NAME`：任务1中创建的RDS数据库名

**任务3步骤：**

1. 确保 `test` CCE集群和 `rds-web` RDS数据库已就绪。获取RDS的内网IP、端口、用户名、密码、数据库名。

2. 在CCE控制台，选择 `test` 集群，导航至“工作负载” -> “无状态负载 (Deployments)”，选择“使用镜像创建”或从“应用市场”搜索WordPress部署。

3. 配置工作负载

   ：按上述参数填写。

   - **容器配置**：镜像选择 `wordpress:php7.3` 或类似。容器端口 `80`。
   - **环境变量**：添加上述4个环境变量 (注意RDS安全组放行3306)。
   - **访问设置 (服务)**：类型 `LoadBalancer`，协议 `TCP`，容器端口 `80`，服务端口 `80`。

4. 创建负载。等待LoadBalancer服务创建完成，获取其外部IP。

5. 浏览器访问 `http://[外部IP地址]:80`，应看到WordPress安装/登录页。

**CCE网络与存储实战**

**任务1：创建CCE集群**

**得分点：**按要求成功配置CCE集群。

集群创建参数： 计费模式: 按需付费；区域:华为-北京四；集群名称: `cce-k8s`；版本: V1.21；规模: 50节点；网络模型: 容器隧道网络；VPC: `vpc-cce`(已预置)；控制节点子网: `subnet-cce`(已预置)；容器网段: 自动选择；服务网段: 默认。

节点创建参数： 计费模式: 按需付费；规格：c6s.xlarge.2 (4核|8GB)；操作系统：公共镜像EulerOS 2.5；名称：`cce-k8s-node-01`；登录：密码 (`Huawei@1234` 建议)；系统盘/数据盘：高IO，40G；子网：默认；弹性公网IP：自动创建 (全动态BGP, 按流量, 带宽5M)。

**注意：** (1) 按指导参数配置，否则不得分。 (2) 若规定节点规格售罄，选相近规格。

**任务1步骤：** 通过华为云CCE控制台操作。

1. **创建集群控制面**：按参数创建名为 `cce-k8s` 的集群。
2. **创建节点**：在 `cce-k8s` 集群中，按参数创建名为 `cce-k8s-node-01` 的节点。

**任务2：安装并配置kubectl**

**得分点：**在ecs-terminal中正确安装kubectl客户端。 下载 `kubeconfig.json` 至 `/home/user/Downloads/kubeconfig.json`。 kubectl客户端 (v1.19.10) 下载链接：`https://dl.k8s.io/v1.19.10/kubernetes-client-linux-amd64.tar.gz` 验证：`kubectl get node` 正常显示节点信息。

**注意：** (1) kubectl需配置于ecs-terminal。 (2) `kubectl get node` 未返回节点信息不得分。

**任务2步骤：** 在ecs-terminal中执行。

1. 下载并解压kubectl：

   <BASH>

   ```
   wget https://dl.k8s.io/v1.19.10/kubernetes-client-linux-amd64.tar.gztar -zxvf kubernetes-client-linux-amd64.tar.gzsudo mv kubernetes/client/bin/kubectl /usr/local/bin/sudo chmod +x /usr/local/bin/kubectlkubectl version --client
   ```

2. **配置kubectl连接集群**： 在华为云CCE控制台 `cce-k8s` 集群的“连接信息”中下载 `kubeconfig` 文件，并按指引配置。可使用 `scp` 将文件上传到ecs-terminal。

3. 验证：

   <BASH>

   ```
   kubectl get node
   ```

   预期显示

    

   ```
   cce-k8s-node-01
   ```

    

   节点信息，状态为

    

   ```
   Ready
   ```

   。

**任务3：创建Deployment**

**得分点：**按指示查看创建后的Deployment。 在 `labfile/servicefile` 目录创建 `nginx-deploy.yaml`。

`nginx-deploy.yaml` 内容：

<YAML>

```
apiVersion: apps/v1kind: Deploymentmetadata:  name: nginxspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx        ports:        - containerPort: 80
```

**任务3步骤：** 在ecs-terminal中执行。

1. 创建目录并进入：

   <BASH>

   ```
   mkdir -p labfile/servicefilecd labfile/servicefile
   ```

2. 创建 `nginx-deploy.yaml` 文件，内容如上。

3. 应用YAML创建Deployment：

   <BASH>

   ```
   kubectl apply -f nginx-deploy.yaml
   ```

4. 查看Deployment：

   <BASH>

   ```
   kubectl get deployment nginx# 或 kubectl get pods -l app=nginx
   ```

   预期

    

   ```
   nginx
   ```

    

   Deployment有3个副本运行。

**任务4：创建Service服务**

**得分点：**在CCE控制台“服务发现”中查看到 `nginx-svc`。 创建 `nginx-service.yaml`。

`nginx-service.yaml` 内容：

<YAML>

```
apiVersion: v1kind: Servicemetadata:  name: nginx-svcspec:  selector:    app: nginx  ports:  - protocol: TCP    port: 8080    targetPort: 80
```

**任务4步骤：** 在ecs-terminal (建议在 `labfile/servicefile` 目录) 中执行。

1. 创建 `nginx-service.yaml` 文件，内容如上。

2. 应用YAML创建Service：

   <BASH>

   ```
   kubectl apply -f nginx-service.yaml
   ```

3. 查看Service和Endpoints：

   <BASH>

   ```
   kubectl get service nginx-svckubectl get endpoints nginx-svc
   ```

   预期Endpoints显示3个Pod的IP和端口。

4. 验证：登录华为云CCE控制台，在 `cce-k8s` 集群的“服务发现”中应能看到 `nginx-svc`。

**基于CCE Kubernetes编排实战**

**实验一：创建CCE集群及创建节点**

**任务1：创建CCE集群及创建节点**

**得分点：**按要求成功配置CCE集群。

集群参数： 计费: 按需；区域: 华为-北京四；名称: `cce-k8s` (必须)；版本: 推荐；规模: 50节点；Master: 单节点；VPC: `vpc-cce`(已预置)；网络: 容器隧道；容器网段: 自动；服务网段: 默认；插件: 关闭云原生监控。

节点参数： 计费: 按需；可用区: 随机；名称: `cce-k8s-node-01`(建议)；规格: c6s.xlarge.2 (4核|8GB)；引擎: Containerd；OS: 公共镜像EulerOS 2.9；系统盘: 高IO,40GiB；数据盘: 高IO,100GiB；子网: 默认；弹性IP: 自动创建 (全动态BGP,按流量,带宽5M)；登录: 密码。

**任务1步骤：** 通过华为云CCE控制台操作。

1. **创建集群控制面**：按参数创建名为 `cce-k8s` 的集群。
2. **创建节点**：在 `cce-k8s` 集群中，按参数创建节点。

**实验二：使用kubectl操作CCE集群**

**任务1：安装并配置kubectl**

**得分点：**在ecs-terminal中正确安装kubectl客户端。 kubectl下载链接：`https://sandbox-experiment-files.obs.cn-north-4.myhuaweicloud.com/1993/kubernetes-client-linux-amd64.tar.gz` 验证：`kubectl get node` 正常显示节点信息。

**任务1步骤：** 在ecs-terminal中执行。

1. 下载并安装kubectl：

   <BASH>

   ```
   wget https://sandbox-experiment-files.obs.cn-north-4.myhuaweicloud.com/1993/kubernetes-client-linux-amd64.tar.gztar -zxvf kubernetes-client-linux-amd64.tar.gzsudo mv kubernetes/client/bin/kubectl /usr/local/bin/sudo chmod +x /usr/local/bin/kubectl
   ```

2. **配置kubectl连接**：参考CCE控制台 `cce-k8s` 集群的“连接信息”下载并配置 `kubeconfig`。

3. 验证：

   <BASH>

   ```
   kubectl get node
   ```

   预期显示节点信息，状态为

    

   ```
   Ready
   ```

   。

**任务2：创建并使用名为“production”的namespace**

**得分点：**于预制CCE集群创建指定namespace。 在 `cce-k8s` 集群创建名为 `production` 的namespace。 **注意：** namespace命名不匹配不得分。

**任务2步骤：**

<BASH>

```
kubectl create namespace productionkubectl get namespace production
```

**任务3：创建并使用名为“testing”的namespace**

**得分点：**于预制CCE集群创建指定namespace。 在 `cce-k8s` 集群创建名为 `testing` 的namespace。 **注意：** namespace命名不匹配不得分。

**任务3步骤：**

<BASH>

```
kubectl create namespace testingkubectl get namespace testing
```

**实验三：在CCE集群中部署Deployment工作负载**

**任务1：使用Deployment部署Nginx**

**得分点：**按照要求成功创建Deployment负载。 于 `cce-k8s` 集群创建Deployment： 名称：`nginx`；命名空间：`production`；副本数：2；镜像：`niginx:1.7.9` (按题目，若为笔误则用 `nginx:1.7.9`)。 **注意：** 名称、命名空间、副本、镜像版本不匹配均不得分。

**任务1步骤：**

<BASH>

```
# 使用题目指定的镜像名kubectl create deployment nginx --image=niginx:1.7.9 --replicas=2 --namespace=production# 或者，如果确认是笔误# kubectl create deployment nginx --image=nginx:1.7.9 --replicas=2 --namespace=productionkubectl get deployment nginx --namespace=productionkubectl get pods --namespace=production -l app=nginx
```

**任务2：更新Deployment**

**得分点：**按照要求更新任务1已创建的Deployment负载。 更新要求：副本数：2 → 3；镜像：`niginx:1.7.9` → `niginx:1.9.1` (或 `nginx:1.9.1`)。 **注意：** 副本数、镜像版本未按要求更新则不得分。

**任务2步骤：**

<BASH>

```
kubectl scale deployment nginx --replicas=3 --namespace=production# 使用题目指定的镜像名kubectl set image deployment/nginx nginx=niginx:1.9.1 --namespace=production# 或者，如果确认是笔误 (假设容器名为nginx)# kubectl set image deployment/nginx nginx=nginx:1.9.1 --namespace=productionkubectl get deployment nginx --namespace=production# 验证Pod镜像 (先获取一个新Pod名称)# kubectl describe pod [pod名称] --namespace=production | grep Image:
```
